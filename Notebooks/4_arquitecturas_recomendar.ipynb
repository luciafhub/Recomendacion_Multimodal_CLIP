{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtPiA58P2Qlc"
      },
      "source": [
        "# Arquitecturas para tareas de recomendación\n",
        "\n",
        "Este notebook implementa y entrena siete arquitecturas distintas para predecir la puntuación (rating) de reseñas de restaurantes. \n",
        "\n",
        "Cada modelo combina, en distinta medida, la codificación tradicional (IDs de usuario y restaurante) con representaciones obtenidas mediante CLIP (texto, imagen o ambos). Se definen clases Dataset específicas para cada tipo de entrada, y se entrena cada arquitectura con diferentes tasas de aprendizaje. Los modelos se evalúan mediante RMSE en los conjuntos de entrenamiento, validación y test, y los resultados se guardan en archivos .xlsx y gráficos .pdf."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importación de librerías\n",
        "\n",
        "Se explica para que se emplea cada una de ella. \n",
        "\n",
        "Si alguna no está instalada, hacer: pip install nombre_paquete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Medición de tiempo de ejecución\n",
        "import time\n",
        "\n",
        "# Gestión de advertencias (por ejemplo, para ignorar ciertos warnings)\n",
        "import warnings\n",
        "\n",
        "# Manipulación de datos en forma de tablas\n",
        "import pandas as pd\n",
        "\n",
        "# Operaciones matemáticas y manejo de arrays\n",
        "import numpy as np\n",
        "\n",
        "# Visualización de gráficos\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Framework principal de deep learning\n",
        "import torch\n",
        "\n",
        "# Definición de redes neuronales en PyTorch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Optimizadores (como Adam) para entrenamiento de modelos\n",
        "import torch.optim as optim\n",
        "\n",
        "# Estructuras Dataset y DataLoader para manejar datos en PyTorch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Barra de progreso para bucles (entrenamiento, carga de datos, etc.)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Solución a errores de importación de NumPy en entornos como Kaggle\n",
        "# Evita conflictos con ciertos módulos internos de NumPy\n",
        "import sys\n",
        "import numpy.core.numeric as _num\n",
        "sys.modules['numpy._core.numeric'] = _num\n",
        "\n",
        "# Cálculo del error cuadrático medio (usado para RMSE)\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj-KB_jo2k8o"
      },
      "source": [
        "## Carga de los datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar los datasets y asegurarse de que son DataFrames\n",
        "def load_pickle_df(path):\n",
        "    obj = pd.read_pickle(path)\n",
        "    return pd.DataFrame(obj) if isinstance(obj, list) else obj\n",
        "\n",
        "train = load_pickle_df(\"/kaggle/input/ny8010/train_v80.pkl\")\n",
        "val   = load_pickle_df(\"/kaggle/input/ny8010/val_v10.pkl\")\n",
        "test  = load_pickle_df(\"/kaggle/input/ny8010/test_v10.pkl\")\n",
        "\n",
        "# Crear columnas 'user_enc' y 'item_enc' con códigos numéricos únicos\n",
        "for df in (train, val, test):\n",
        "    df['user_enc'] = df['user_id_new'].astype('category').cat.codes\n",
        "    df['item_enc'] = df['restaurant_id_new'].astype('category').cat.codes\n",
        "\n",
        "# Mostrar información básica de los datasets\n",
        "print(\"Número de datos\")\n",
        "print(f\"\\nTrain: {len(train)}\\nVal: {len(val)}\\nTest: {len(test)}\\nTotal: {len(train) + len(val) + len(test)}\")\n",
        "\n",
        "print(\"\\nColumnas\")\n",
        "print(train.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDw17rDm2cFw"
      },
      "source": [
        "##  Evaluación de baseline\n",
        "\n",
        "Este bloque evalúa un modelo baseline que predice siempre la media global de los ratings del conjunto de entrenamiento. Calcula el RMSE de esta predicción constante en train, val y test como referencia inicial para comparar otros modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ft49NNq2LwB"
      },
      "outputs": [],
      "source": [
        "# Asegurar que la columna 'rating' esté en formato float en los tres conjuntos\n",
        "for df in (train, val, test):\n",
        "    df['rating'] = df['rating'].astype(float)\n",
        "\n",
        "# Definición de la función para calcular el RMSE\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# Baseline: media global del conjunto de entrenamiento\n",
        "global_mean = train['rating'].mean()\n",
        "\n",
        "# Evaluación del baseline sin guardar el nombre del dataset\n",
        "rmse_train = rmse(train['rating'], np.full(len(train), global_mean))\n",
        "rmse_val   = rmse(val['rating'],   np.full(len(val), global_mean))\n",
        "rmse_test  = rmse(test['rating'],  np.full(len(test), global_mean))\n",
        "\n",
        "# Mostrar resultados directamente\n",
        "print(\"\\nRMSE del baseline (media global):\")\n",
        "print(f\"Train: {rmse_train:.4f}\")\n",
        "print(f\"Val:   {rmse_val:.4f}\")\n",
        "print(f\"Test:  {rmse_test:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXdRDO642JMO"
      },
      "source": [
        "# Configuración general y definición de hiperparámetros\n",
        "\n",
        "Se configura el entorno que se usará en Kaggle y se establecen los valores de los hiperparámetros que se usan para las distintos modelos de predicción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py4Baxt_ykuE"
      },
      "outputs": [],
      "source": [
        "# Ignora los avisos de tipo FutureWarning (por ejemplo, de pandas o sklearn)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Selecciona el dispositivo de ejecución: GPU si está disponible, sino CPU\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Activa AMP (Automatic Mixed Precision) si se entrena en GPU, para acelerar el entrenamiento reduciendo consumo de memoria\n",
        "use_amp = DEVICE == \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HIPERPARÁMETROS:\n",
        "\n",
        "# Tamaño del batch usado por los DataLoaders (número de ejemplos por iteración)\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Número máximo de épocas (iteraciones completas sobre los datos) para entrenar cada modelo\n",
        "MAX_EPOCHS = 1000\n",
        "\n",
        "# Número de épocas consecutivas sin mejora en validación antes de detener el entrenamiento (early stopping)\n",
        "PATIENCE = 10\n",
        "\n",
        "# Dimensión de los vectores de embedding aprendidos para usuarios e ítems (solo se usa en arquitecturas con IDs)\n",
        "EMB_DIM = 50\n",
        "\n",
        "# Número de neuronas en la capa oculta de los modelos MLP (redes neuronales)\n",
        "HIDDEN_DIM = 64\n",
        "\n",
        "# Lista de tasas de aprendizaje a explorar durante el entrenamiento (controla la magnitud de los pasos de actualización)\n",
        "LR_LIST = [1e-5, 1e-4, 5e-4, 1e-3]\n",
        "\n",
        "# Parámetro de regularización L2 (weight decay) que penaliza pesos grandes y ayuda a prevenir el sobreajuste\n",
        "WEIGHT_DECAY = 1e-6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDUOixqVys9m"
      },
      "source": [
        "## Definición de clases Dataset personalizadas\n",
        "\n",
        "Las clases Dataset personalizadas definen cómo se organizan y extraen los datos desde un DataFrame para adaptarlos al entrenamiento de modelos en PyTorch. Cada clase está diseñada para un tipo específico de entrada: algunas usan identificadores numéricos de usuario y restaurante (FM_Dataset), otras trabajan con embeddings de texto o imagen generados previamente (CLIPTextDataset, CLIPImageDataset), y otras combinan distintas fuentes de información (MixedDataset, FullDataset). Estas clases son necesarias para que PyTorch pueda acceder a los datos de forma estructurada y eficiente.\n",
        "\n",
        "A partir de estas clases, se crean objetos llamados DataLoaders, que se encargan de cargar los datos por lotes (batches), barajarlos si es necesario, y alimentar automáticamente al modelo durante el entrenamiento y validación. Esto permite aprovechar mejor la GPU, reducir el consumo de memoria y facilitar el entrenamiento con datasets grandes. \n",
        "\n",
        "En resumen, Dataset define cómo se obtienen los datos, y DataLoader gestiona cómo se entregan al modelo en cada iteración."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkVNv-O7yv3o"
      },
      "outputs": [],
      "source": [
        "# Dataset clásico basado en codificación de usuario e ítem con sus IDs\n",
        "class FM_Dataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        # Convierte las columnas de IDs y rating a tensores de PyTorch\n",
        "        self.u = torch.tensor(df['user_id_new'].values, dtype=torch.long)\n",
        "        self.i = torch.tensor(df['restaurant_id_new'].values, dtype=torch.long)\n",
        "        self.r = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
        "    def __len__(self): return len(self.r)\n",
        "    def __getitem__(self, idx): return self.u[idx], self.i[idx], self.r[idx]\n",
        "\n",
        "# Dataset para modelos que usan embeddings CLIP de texto como entrada\n",
        "class CLIPTextDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        # Combina los vectores de texto en una matriz y convierte a tensor\n",
        "        self.x = torch.from_numpy(np.vstack(df['text_emb'].values)).float()\n",
        "        self.y = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx): return self.x[idx], self.y[idx]\n",
        "\n",
        "# Dataset mixto que combina IDs con embeddings CLIP de texto\n",
        "class MixedDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.u = torch.tensor(df['user_id_new'].values, dtype=torch.long)\n",
        "        self.i = torch.tensor(df['restaurant_id_new'].values, dtype=torch.long)\n",
        "        self.x = torch.from_numpy(np.vstack(df['text_emb'].values)).float()\n",
        "        self.r = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
        "    def __len__(self): return len(self.r)\n",
        "    def __getitem__(self, idx): return self.u[idx], self.i[idx], self.x[idx], self.r[idx]\n",
        "\n",
        "# Dataset para modelos que usan solo embeddings CLIP de imagen como entrada\n",
        "class CLIPImageDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.x = torch.from_numpy(np.stack(df['image_emb'].values)).float()\n",
        "        self.y = torch.tensor(df['rating'].astype(float).values, dtype=torch.float32)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx): return self.x[idx], self.y[idx]\n",
        "\n",
        "# Dataset para modelos que combinan embeddings CLIP de imagen y texto\n",
        "class CLIPMixedDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        # Concatena los embeddings de imagen y texto horizontalmente (por columnas)\n",
        "        img_emb = np.stack(df['image_emb'].values)\n",
        "        txt_emb = np.stack(df['text_emb'].values)\n",
        "        self.x = torch.from_numpy(np.concatenate([img_emb, txt_emb], axis=1)).float()\n",
        "        self.y = torch.tensor(df['rating'].astype(float).values, dtype=torch.float32)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx): return self.x[idx], self.y[idx]\n",
        "\n",
        "# Dataset más completo: incluye IDs, embeddings de imagen y de texto\n",
        "class FullDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.u = torch.tensor(df['user_enc'].values, dtype=torch.long)\n",
        "        self.i = torch.tensor(df['item_enc'].values, dtype=torch.long)\n",
        "        img_emb = np.stack(df['image_emb'].values)\n",
        "        txt_emb = np.stack(df['text_emb'].values)\n",
        "        self.x = torch.from_numpy(np.concatenate([img_emb, txt_emb], axis=1)).float()\n",
        "        self.y = torch.tensor(df['rating'].astype(float).values, dtype=torch.float32)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx): return self.u[idx], self.i[idx], self.x[idx], self.y[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwJ4mdEc1MQY"
      },
      "source": [
        "## Arquitecturas para predecir las reseñas\n",
        "\n",
        "Se implementan siete arquitecturas diferentes en PyTorch para predecir ratings de restaurantes, combinando embeddings clásicos (IDs) y multimodales (texto e imagen) mediante factorización, MLPs y modelos mixtos.\n",
        "\n",
        "\n",
        "#### Tabla resumen de arquitecturas de recomendación\n",
        "\n",
        "| Nº | Nombre del Modelo           | Entradas utilizadas                                  | Tipo de arquitectura         | Comentario breve |\n",
        "|----|-----------------------------|------------------------------------------------------|------------------------------|------------------|\n",
        "| 1  | MatrixFactorization         | ID de usuario + ID de restaurante                    | Producto punto               | Factorización clásica sin red neuronal |\n",
        "| 2  | NeuralRecommender           | ID de usuario + ID de restaurante                    | MLP                          | Recomendador neuronal que concatena embeddings |\n",
        "| 3  | CLIPTextRegressor           | Embedding CLIP del texto                             | MLP                          | Solo utiliza el contenido textual |\n",
        "| 4  | MixedModel                  | ID de usuario + ID de restaurante + texto emb       | MLP                          | Mezcla codificación tradicional con texto |\n",
        "| 5  | CLIPImageRegressor          | Embedding CLIP de imagen                             | MLP                          | Solo utiliza el contenido visual |\n",
        "| 6  | CLIPMixedRegressor          | Embedding CLIP de imagen + texto                    | MLP                          | Fusiona ambos tipos de contenido multimodal |\n",
        "| 7  | FullModel                   | ID de usuario + ID de restaurante + img + texto     | MLP                          | Modelo más completo, combina IDs y multimodalidad |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlvnNu-k1Lra"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# Definición de modelos de recomendación\n",
        "# ============================================\n",
        "\n",
        "# Arquitectura 1: Factorización Matricial\n",
        "# Aprende un vector de características (embedding) por usuario y por ítem.\n",
        "# La predicción del rating se obtiene como el producto punto entre ambos embeddings.\n",
        "class MatrixFactorization(nn.Module):\n",
        "    def __init__(self, n_users, n_items):\n",
        "        super().__init__()\n",
        "        # Embeddings para usuarios e ítems\n",
        "        self.Eu = nn.Embedding(n_users, EMB_DIM)\n",
        "        self.Ei = nn.Embedding(n_items, EMB_DIM)\n",
        "        # Inicialización normal de pesos\n",
        "        nn.init.normal_(self.Eu.weight, mean=1.0, std=0.01)\n",
        "        nn.init.normal_(self.Ei.weight, mean=1.0, std=0.01)\n",
        "\n",
        "    def forward(self, u, i):\n",
        "        # Producto punto entre los embeddings del usuario y del ítem\n",
        "        return (self.Eu(u) * self.Ei(i)).sum(dim=1)\n",
        "\n",
        "# Arquitectura 2: Recomendador neuronal (MLP)\n",
        "# Similar a la anterior, pero en vez de usar producto punto, combina los embeddings con una red neuronal.\n",
        "class NeuralRecommender(nn.Module):\n",
        "    def __init__(self, n_users, n_items):\n",
        "        super().__init__()\n",
        "        # Embeddings para usuarios e ítems\n",
        "        self.user_emb = nn.Embedding(n_users, EMB_DIM)\n",
        "        self.item_emb = nn.Embedding(n_items, EMB_DIM)\n",
        "        # Inicialización normal de pesos\n",
        "        nn.init.normal_(self.user_emb.weight, mean=1.0, std=0.01)\n",
        "        nn.init.normal_(self.item_emb.weight, mean=1.0, std=0.01)\n",
        "        # Red neuronal para predecir el rating a partir de los embeddings concatenados\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * EMB_DIM, HIDDEN_DIM),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(HIDDEN_DIM, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, u, i):\n",
        "        # Concatenación de los embeddings de usuario e ítem\n",
        "        x = torch.cat([self.user_emb(u), self.item_emb(i)], dim=1)\n",
        "        # Predicción del rating\n",
        "        return self.mlp(x).squeeze(1)\n",
        "\n",
        "# Arquitecturas 3, 5 y 6: Regresores para embeddings (texto, imagen o combinación)\n",
        "# Red neuronal que toma directamente un vector (embedding CLIP) como entrada y predice un rating.\n",
        "class CLIPRegressor(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        # Red MLP con 3 capas para regresión\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_dim, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x).squeeze(1)\n",
        "\n",
        "# Arquitectura 4: Modelo mixto (IDs + embeddings de texto)\n",
        "# Combina los embeddings de usuario e ítem con los vectores CLIP de texto.\n",
        "class MixedModel(nn.Module):\n",
        "    def __init__(self, n_users, n_items, clip_dim):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding(n_users, EMB_DIM)\n",
        "        self.item_emb = nn.Embedding(n_items, EMB_DIM)\n",
        "        nn.init.normal_(self.user_emb.weight, mean=1.0, std=0.01)\n",
        "        nn.init.normal_(self.item_emb.weight, mean=1.0, std=0.01)\n",
        "        # MLP que procesa los embeddings junto con el texto\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(clip_dim + 2 * EMB_DIM, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, u, i, x):\n",
        "        # Concatenación de embeddings de usuario, ítem y texto CLIP\n",
        "        x = torch.cat([self.user_emb(u), self.item_emb(i), x], dim=1)\n",
        "        return self.mlp(x).squeeze(1)\n",
        "\n",
        "# Arquitectura 7: Modelo completo (IDs + imagen + texto)\n",
        "# Utiliza toda la información disponible: IDs, embeddings CLIP de imagen y de texto.\n",
        "class FullModel(nn.Module):\n",
        "    def __init__(self, n_users, n_items, clip_dim=1024, emb_dim=50):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding(n_users, emb_dim)\n",
        "        self.item_emb = nn.Embedding(n_items, emb_dim)\n",
        "        nn.init.normal_(self.user_emb.weight, mean=1.0, std=0.01)\n",
        "        nn.init.normal_(self.item_emb.weight, mean=1.0, std=0.01)\n",
        "        # MLP que combina embeddings de usuario, ítem y embeddings CLIP (texto + imagen)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(clip_dim + 2 * emb_dim, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, u, i, x):\n",
        "        # Concatenación de toda la información (IDs + texto + imagen)\n",
        "        concat = torch.cat([self.user_emb(u), self.item_emb(i), x], dim=1)\n",
        "        return self.mlp(concat).squeeze(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VWoHccrykar"
      },
      "source": [
        "## Entrenamiento y Evaluación de Modelos de Recomendación\n",
        "\n",
        "Este bloque define las funciones necesarias para entrenar y evaluar modelos de recomendación. Incluye una función para calcular el error RMSE, otra que adapta la entrada según el tipo de modelo, y una función principal train_model que entrena el modelo usando validación y early stopping, prueba diferentes tasas de aprendizaje y guarda los resultados y curvas de entrenamiento en archivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7Lsu33x16S0"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# Funciones auxiliares: entrenamiento y evaluación\n",
        "# ============================================\n",
        "\n",
        "# Función para calcular el RMSE en un conjunto de datos (validación o test)\n",
        "def compute_rmse(model, loader, criterion):\n",
        "    model.eval()  # Se pone el modelo en modo evaluación (desactiva dropout, batchnorm, etc.)\n",
        "    total, n = 0.0, 0\n",
        "    with torch.no_grad():  # No se calculan gradientes\n",
        "        for batch in loader:\n",
        "            batch = [b.to(DEVICE) for b in batch]  # Se envían los tensores al dispositivo\n",
        "            pred, y = forward_batch(model, batch)  # Se obtienen predicciones y etiquetas reales\n",
        "            loss = criterion(pred, y)  # Se calcula el error cuadrático medio\n",
        "            total += loss.item() * y.size(0)  # Se acumula el error total\n",
        "            n += y.size(0)  # Se acumulan las muestras procesadas\n",
        "    return np.sqrt(total / n)  # Se devuelve la raíz del error cuadrático medio (RMSE)\n",
        "\n",
        "# Función generalizada para hacer forward pass compatible con distintos tipos de entrada\n",
        "def forward_batch(model, batch):\n",
        "    if len(batch) == 2:\n",
        "        # Casos con solo features (x) y etiquetas (y)\n",
        "        x, y = batch\n",
        "        pred = model(x)\n",
        "    elif len(batch) == 3:\n",
        "        # Casos con user ID, item ID y etiquetas (factorización matricial o MLP con IDs)\n",
        "        u, i, y = batch\n",
        "        pred = model(u, i)\n",
        "    else:\n",
        "        # Casos con user ID, item ID, embeddings (texto/imagen) y etiquetas\n",
        "        u, i, x, y = batch\n",
        "        pred = model(u, i, x)\n",
        "    return pred, y\n",
        "\n",
        "# Función principal para entrenar un modelo con validación y early stopping\n",
        "def train_model(name, model_class, dataset_class, train_df, val_df, test_df, extra_args={}):\n",
        "    print(f\"\\n===> Entrenando {name}\")\n",
        "\n",
        "    # Creación de DataLoaders para entrenamiento, validación y test\n",
        "    train_loader = DataLoader(dataset_class(train_df), batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader   = DataLoader(dataset_class(val_df), batch_size=BATCH_SIZE)\n",
        "    test_loader  = DataLoader(dataset_class(test_df), batch_size=BATCH_SIZE)\n",
        "\n",
        "    criterion = nn.MSELoss()  # Se utiliza el error cuadrático medio como función de pérdida\n",
        "    results = []  # Lista para almacenar resultados por tasa de aprendizaje\n",
        "\n",
        "    # Se entrena el modelo con distintas tasas de aprendizaje\n",
        "    for lr in LR_LIST:\n",
        "        model = model_class(**extra_args).to(DEVICE)  # Se inicializa el modelo\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=WEIGHT_DECAY)  # Optimizador Adam\n",
        "        scaler = torch.cuda.amp.GradScaler() if use_amp else None  # Escalado automático de precisión (AMP)\n",
        "\n",
        "        # Variables para early stopping\n",
        "        best_val, best_state, best_epoch = float('inf'), None, 0\n",
        "        train_hist, val_hist = [], []\n",
        "        no_improve = 0\n",
        "\n",
        "        # Entrenamiento por épocas\n",
        "        for epoch in tqdm(range(1, MAX_EPOCHS + 1), desc=f\"{name} lr={lr}\"):\n",
        "            model.train()\n",
        "            total_loss, count = 0.0, 0\n",
        "\n",
        "            for batch in train_loader:\n",
        "                batch = [b.to(DEVICE) for b in batch]\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                if use_amp:\n",
        "                    # Entrenamiento con AMP (si se usa)\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        pred, y = forward_batch(model, batch)\n",
        "                        loss = criterion(pred, y)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    # Entrenamiento clásico sin AMP\n",
        "                    pred, y = forward_batch(model, batch)\n",
        "                    loss = criterion(pred, y)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                total_loss += loss.item() * y.size(0)\n",
        "                count += y.size(0)\n",
        "\n",
        "            # Evaluación tras cada época\n",
        "            train_rmse = np.sqrt(total_loss / count)\n",
        "            val_rmse = compute_rmse(model, val_loader, criterion)\n",
        "            train_hist.append(train_rmse)\n",
        "            val_hist.append(val_rmse)\n",
        "\n",
        "            # Verificación para early stopping\n",
        "            if val_rmse < best_val:\n",
        "                best_val, best_state, best_epoch = val_rmse, model.state_dict(), epoch\n",
        "                no_improve = 0\n",
        "            else:\n",
        "                no_improve += 1\n",
        "                if no_improve >= PATIENCE:  # No mejora tras 'PATIENCE' épocas\n",
        "                    break\n",
        "\n",
        "        # Se carga el mejor modelo y se evalúa en test\n",
        "        model.load_state_dict(best_state)\n",
        "        test_rmse = compute_rmse(model, test_loader, criterion)\n",
        "\n",
        "        # Se guarda el resultado para esta tasa de aprendizaje\n",
        "        results.append({\n",
        "            'Arquitectura': name,\n",
        "            'learning_rate': lr,\n",
        "            'train_rmse': train_hist[best_epoch - 1],\n",
        "            'val_rmse': best_val,\n",
        "            'test_rmse': test_rmse,\n",
        "            'epochs': best_epoch\n",
        "        })\n",
        "\n",
        "        # Guardado de la curva de entrenamiento\n",
        "        plt.figure()\n",
        "        plt.plot(train_hist, label='Train RMSE')\n",
        "        plt.plot(val_hist, label='Val RMSE')\n",
        "        plt.axvline(best_epoch, linestyle='--', color='gray', label='Best Epoch')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('RMSE')\n",
        "        plt.title(f'{name} @ lr={lr}')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'curve_{name.replace(\"-\", \"_\")}_lr_{lr}.pdf')\n",
        "        plt.close()\n",
        "\n",
        "    # Exportación de resultados a Excel\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_excel(f\"{name}.xlsx\", index=False)\n",
        "    print(f\"Resultados guardados en {name}.xlsx\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejecución del Entrenamiento para Distintas Arquitecturas\n",
        "\n",
        "Se define y entrena una lista de modelos de recomendación, cada uno con su arquitectura, conjunto de datos y parámetros necesarios. Cada modelo se entrena y evalúa utilizando la función train_model, y se registra el tiempo total requerido para completar el proceso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# Lista de arquitecturas a entrenar\n",
        "# ============================================\n",
        "\n",
        "# Cada tupla incluye:\n",
        "# - Nombre del modelo\n",
        "# - Clase del modelo (PyTorch)\n",
        "# - Dataset correspondiente\n",
        "# - Parámetros adicionales requeridos (como nº de usuarios, ítems o dimensión de embeddings)\n",
        "\n",
        "ARQUITECTURAS = [\n",
        "    (\"1-FM\", MatrixFactorization, FM_Dataset, {'n_users': train['user_id_new'].nunique(), 'n_items': train['restaurant_id_new'].nunique()}),\n",
        "    (\"2-RN\", NeuralRecommender, FM_Dataset, {'n_users': train['user_id_new'].nunique(), 'n_items': train['restaurant_id_new'].nunique()}),\n",
        "    (\"3-CLIP-TEXT\", CLIPRegressor, CLIPTextDataset, {'input_dim': len(train['text_emb'].iloc[0])}),\n",
        "    (\"4-MIX-TXTEN\", MixedModel, MixedDataset, {'n_users': train['user_id_new'].nunique(), 'n_items': train['restaurant_id_new'].nunique(), 'clip_dim': len(train['text_emb'].iloc[0])}),\n",
        "    (\"5-CLIP-IMG\", CLIPRegressor, CLIPImageDataset, {'input_dim': len(train['image_emb'].iloc[0])}),\n",
        "    (\"6-TXT+IMG\", CLIPRegressor, CLIPMixedDataset, {'input_dim': len(train['image_emb'].iloc[0]) + len(train['text_emb'].iloc[0])}),\n",
        "    (\"7-FULL\", FullModel, FullDataset, {'n_users': train['user_enc'].nunique(), 'n_items': train['item_enc'].nunique()})\n",
        "]\n",
        "\n",
        "# Entrenamiento de todas las arquitecturas con evaluación y guardado\n",
        "start_all = time.time()\n",
        "for name, model_cls, dataset_cls, extra_args in ARQUITECTURAS:\n",
        "    train_model(name, model_cls, dataset_cls, train, val, test, extra_args)\n",
        "print(f\"\\nTiempo total: {(time.time() - start_all)/60:.2f} minutos\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
